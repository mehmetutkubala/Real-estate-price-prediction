{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ab5c8d3",
   "metadata": {},
   "source": [
    "# Real estate price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73e63dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\",100)\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630a25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Real estate.csv\") #https://www.kaggle.com/datasets/quantbruce/real-estate-price-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd88425",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fc757eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>X1 transaction date</th>\n",
       "      <th>X2 house age</th>\n",
       "      <th>X3 distance to the nearest MRT station</th>\n",
       "      <th>X4 number of convenience stores</th>\n",
       "      <th>X5 latitude</th>\n",
       "      <th>X6 longitude</th>\n",
       "      <th>Y house price of unit area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012.917</td>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012.917</td>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013.583</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013.500</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2012.833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>410</td>\n",
       "      <td>2013.000</td>\n",
       "      <td>13.7</td>\n",
       "      <td>4082.01500</td>\n",
       "      <td>0</td>\n",
       "      <td>24.94155</td>\n",
       "      <td>121.50381</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>411</td>\n",
       "      <td>2012.667</td>\n",
       "      <td>5.6</td>\n",
       "      <td>90.45606</td>\n",
       "      <td>9</td>\n",
       "      <td>24.97433</td>\n",
       "      <td>121.54310</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>412</td>\n",
       "      <td>2013.250</td>\n",
       "      <td>18.8</td>\n",
       "      <td>390.96960</td>\n",
       "      <td>7</td>\n",
       "      <td>24.97923</td>\n",
       "      <td>121.53986</td>\n",
       "      <td>40.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>413</td>\n",
       "      <td>2013.000</td>\n",
       "      <td>8.1</td>\n",
       "      <td>104.81010</td>\n",
       "      <td>5</td>\n",
       "      <td>24.96674</td>\n",
       "      <td>121.54067</td>\n",
       "      <td>52.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>414</td>\n",
       "      <td>2013.500</td>\n",
       "      <td>6.5</td>\n",
       "      <td>90.45606</td>\n",
       "      <td>9</td>\n",
       "      <td>24.97433</td>\n",
       "      <td>121.54310</td>\n",
       "      <td>63.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      No  X1 transaction date  X2 house age  \\\n",
       "0      1             2012.917          32.0   \n",
       "1      2             2012.917          19.5   \n",
       "2      3             2013.583          13.3   \n",
       "3      4             2013.500          13.3   \n",
       "4      5             2012.833           5.0   \n",
       "..   ...                  ...           ...   \n",
       "409  410             2013.000          13.7   \n",
       "410  411             2012.667           5.6   \n",
       "411  412             2013.250          18.8   \n",
       "412  413             2013.000           8.1   \n",
       "413  414             2013.500           6.5   \n",
       "\n",
       "     X3 distance to the nearest MRT station  X4 number of convenience stores  \\\n",
       "0                                  84.87882                               10   \n",
       "1                                 306.59470                                9   \n",
       "2                                 561.98450                                5   \n",
       "3                                 561.98450                                5   \n",
       "4                                 390.56840                                5   \n",
       "..                                      ...                              ...   \n",
       "409                              4082.01500                                0   \n",
       "410                                90.45606                                9   \n",
       "411                               390.96960                                7   \n",
       "412                               104.81010                                5   \n",
       "413                                90.45606                                9   \n",
       "\n",
       "     X5 latitude  X6 longitude  Y house price of unit area  \n",
       "0       24.98298     121.54024                        37.9  \n",
       "1       24.98034     121.53951                        42.2  \n",
       "2       24.98746     121.54391                        47.3  \n",
       "3       24.98746     121.54391                        54.8  \n",
       "4       24.97937     121.54245                        43.1  \n",
       "..           ...           ...                         ...  \n",
       "409     24.94155     121.50381                        15.4  \n",
       "410     24.97433     121.54310                        50.0  \n",
       "411     24.97923     121.53986                        40.6  \n",
       "412     24.96674     121.54067                        52.5  \n",
       "413     24.97433     121.54310                        63.9  \n",
       "\n",
       "[414 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3361c327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No                                        0\n",
       "X1 transaction date                       0\n",
       "X2 house age                              0\n",
       "X3 distance to the nearest MRT station    0\n",
       "X4 number of convenience stores           0\n",
       "X5 latitude                               0\n",
       "X6 longitude                              0\n",
       "Y house price of unit area                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() #We examine the empty lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac1cede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 414 entries, 0 to 413\n",
      "Data columns (total 8 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   No                                      414 non-null    int64  \n",
      " 1   X1 transaction date                     414 non-null    float64\n",
      " 2   X2 house age                            414 non-null    float64\n",
      " 3   X3 distance to the nearest MRT station  414 non-null    float64\n",
      " 4   X4 number of convenience stores         414 non-null    int64  \n",
      " 5   X5 latitude                             414 non-null    float64\n",
      " 6   X6 longitude                            414 non-null    float64\n",
      " 7   Y house price of unit area              414 non-null    float64\n",
      "dtypes: float64(6), int64(2)\n",
      "memory usage: 26.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f7bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns ={'X2 house age':'house_age'},inplace=True)\n",
    "df.rename(columns ={'X3 distance to the nearest MRT station':'distance_to_the_nearest_MRT_station'},inplace=True)\n",
    "df.rename(columns ={'X4 number of convenience stores':'number_of_convenience_stores'},inplace=True)\n",
    "df.rename(columns ={'X5 latitude':'latitude'},inplace=True)\n",
    "df.rename(columns ={'X6 longitude':'longitude'},inplace=True)\n",
    "df.rename(columns ={'Y house price of unit area':'house_price_of_unit_area'},inplace=True)\n",
    "df.rename(columns ={'X1 transaction date':'transaction_date'},inplace=True)\n",
    "#We change the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d14190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transaction_date\"]=df[\"transaction_date\"].astype(\"int\") #We change the type of data in transaction_date to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11eccb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013    288\n",
       "2012    126\n",
       "Name: transaction_date, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transaction_date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8d9b8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house_price_of_unit_area               1.000000\n",
       "number_of_convenience_stores           0.571005\n",
       "latitude                               0.546307\n",
       "longitude                              0.523287\n",
       "transaction_date                       0.081545\n",
       "No                                     0.028587\n",
       "house_age                              0.210567\n",
       "distance_to_the_nearest_MRT_station    0.673613\n",
       "Name: house_price_of_unit_area, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(df.corr()[\"house_price_of_unit_area\"].sort_values(ascending=False)) #We look at their correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a2578",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc59092f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=df.drop([\"No\",\"house_price_of_unit_area\",\"transaction_date\"],axis=1),df[[\"house_price_of_unit_area\"]]\n",
    "x=scaler.fit_transform(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c5ca706",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3554aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96898337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34/34 [==============================] - 1s 11ms/step - loss: 544.7482 - val_loss: 133.2844\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 111.0244 - val_loss: 47.9573\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 88.0896 - val_loss: 77.4394\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 84.2519 - val_loss: 43.8768\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 80.3640 - val_loss: 47.5619\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 120.0075 - val_loss: 45.2188\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 76.8272 - val_loss: 41.3398\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 73.9613 - val_loss: 47.5385\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 71.8498 - val_loss: 51.8938\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 75.4348 - val_loss: 46.0146\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 74.3185 - val_loss: 58.7345\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 89.4495 - val_loss: 49.7462\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 76.3692 - val_loss: 76.7539\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 72.9360 - val_loss: 44.1223\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 66.9636 - val_loss: 47.6499\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 84.5581 - val_loss: 45.0361\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 66.0773 - val_loss: 42.7722\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 71.1243 - val_loss: 52.8482\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 111.2389 - val_loss: 39.6928\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 73.5227 - val_loss: 45.0677\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 72.3120 - val_loss: 60.8985\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 73.3882 - val_loss: 43.0987\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 73.2663 - val_loss: 55.4533\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 70.7639 - val_loss: 46.2941\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 71.8744 - val_loss: 42.5287\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 67.9995 - val_loss: 38.6828\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 84.4684 - val_loss: 153.8296\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 102.0073 - val_loss: 41.9217\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 69.6598 - val_loss: 42.2783\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 67.6119 - val_loss: 39.0872\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 68.2718 - val_loss: 54.0586\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 74.6569 - val_loss: 38.3034\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.2657 - val_loss: 41.7605\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 73.7373 - val_loss: 45.9571\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 66.0008 - val_loss: 40.3859\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 62.0629 - val_loss: 39.4597\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 70.1185 - val_loss: 43.3263\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 65.7330 - val_loss: 39.3619\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 65.2145 - val_loss: 51.1936\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 70.4771 - val_loss: 43.9782\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 83.6698 - val_loss: 62.5057\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 66.2934 - val_loss: 39.5159\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.2132 - val_loss: 52.2399\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 68.3284 - val_loss: 45.6952\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.1441 - val_loss: 48.8451\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 70.2362 - val_loss: 59.9027\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 66.6201 - val_loss: 42.3431\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 66.0206 - val_loss: 42.8435\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.5981 - val_loss: 48.7690\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 68.7035 - val_loss: 41.2107\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.8337 - val_loss: 40.2214\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 62.8108 - val_loss: 87.3430\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 85.7704 - val_loss: 47.6047\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 70.7442 - val_loss: 37.9573\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.4044 - val_loss: 67.7659\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.8605 - val_loss: 67.8074\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 91.6242 - val_loss: 40.6801\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 69.6858 - val_loss: 37.6925\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 67.8570 - val_loss: 52.1460\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 68.5384 - val_loss: 53.8280\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 73.1265 - val_loss: 39.3799\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 64.2669 - val_loss: 41.3133\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.3488 - val_loss: 36.8293\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.7512 - val_loss: 46.0047\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 67.4502 - val_loss: 39.4011\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.7955 - val_loss: 39.8592\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.0274 - val_loss: 38.7039\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 68.0644 - val_loss: 53.4325\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 69.2268 - val_loss: 61.3670\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 66.0815 - val_loss: 46.2652\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 62.1290 - val_loss: 39.0705\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.1805 - val_loss: 46.3904\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.1508 - val_loss: 55.1770\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 73.7899 - val_loss: 38.9971\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.8003 - val_loss: 38.3510\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.8423 - val_loss: 39.3848\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.7879 - val_loss: 42.4518\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.2753 - val_loss: 57.8246\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.4937 - val_loss: 38.8678\n",
      "Epoch 80/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 64.9396 - val_loss: 44.5920\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 67.2312 - val_loss: 40.2314\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 64.3644 - val_loss: 41.3634\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 65.7397 - val_loss: 42.7677\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.0524 - val_loss: 42.2932\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.6569 - val_loss: 42.3085\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.6959 - val_loss: 53.7143\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.3544 - val_loss: 40.8153\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.5348 - val_loss: 40.6430\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.2069 - val_loss: 40.6274\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.9835 - val_loss: 47.0984\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.6248 - val_loss: 47.4391\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.3022 - val_loss: 38.8987\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.7351 - val_loss: 43.7390\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.7823 - val_loss: 62.6094\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.1817 - val_loss: 39.9176\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.0345 - val_loss: 37.1639\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 67.0305 - val_loss: 58.8598\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 64.4698 - val_loss: 38.4708\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.7305 - val_loss: 42.8667\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.3968 - val_loss: 58.0038\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.3357 - val_loss: 43.5216\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.1991 - val_loss: 47.4272\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.3882 - val_loss: 51.9551\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 82.6470 - val_loss: 95.5174\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 75.3964 - val_loss: 39.3979\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 75.6804 - val_loss: 64.8214\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 68.5660 - val_loss: 40.5249\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.1765 - val_loss: 52.9543\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.2024 - val_loss: 44.7509\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.6475 - val_loss: 46.2328\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 67.1353 - val_loss: 40.6946\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.7437 - val_loss: 60.3790\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.0842 - val_loss: 40.4810\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 56.8243 - val_loss: 45.3874\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 67.0437 - val_loss: 49.0530\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.1366 - val_loss: 61.4240\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.5920 - val_loss: 150.2029\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 190.9547 - val_loss: 47.7677\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 65.1631 - val_loss: 44.3606\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 64.0559 - val_loss: 45.0356\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 62.5614 - val_loss: 45.6953\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 81.2208 - val_loss: 70.3069\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.4675 - val_loss: 46.6248\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 69.7120 - val_loss: 63.8952\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 75.9267 - val_loss: 56.6190\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.4390 - val_loss: 55.1272\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.0537 - val_loss: 39.0434\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.1330 - val_loss: 39.8673\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.3585 - val_loss: 39.4967\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.5727 - val_loss: 39.2709\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.4678 - val_loss: 38.9848\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.0922 - val_loss: 38.4836\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.4469 - val_loss: 39.1046\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.5528 - val_loss: 43.1441\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.7115 - val_loss: 43.7057\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.9630 - val_loss: 41.0468\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.9249 - val_loss: 40.0078\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.4213 - val_loss: 41.4017\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 64.6672 - val_loss: 41.4090\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.8354 - val_loss: 37.7656\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.6842 - val_loss: 58.2462\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.5165 - val_loss: 38.3425\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.1141 - val_loss: 39.1377\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.7749 - val_loss: 37.7757\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.3131 - val_loss: 39.8750\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.4882 - val_loss: 40.0712\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.2662 - val_loss: 49.9509\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.4272 - val_loss: 38.1925\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.1405 - val_loss: 41.4564\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.6846 - val_loss: 37.5437\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.2508 - val_loss: 43.7670\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.9462 - val_loss: 38.8758\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.6620 - val_loss: 45.1898\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.8482 - val_loss: 59.1980\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.1338 - val_loss: 38.9610\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.7628 - val_loss: 43.7431\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.0210 - val_loss: 50.1933\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 66.2524 - val_loss: 37.9678\n",
      "Epoch 159/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 72.0453 - val_loss: 37.0536\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 65.2724 - val_loss: 41.3303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.9424 - val_loss: 43.3899\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.5456 - val_loss: 37.0943\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.1122 - val_loss: 40.7493\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 64.9080 - val_loss: 72.4423\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.4061 - val_loss: 39.3464\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.1137 - val_loss: 37.6010\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 58.7782 - val_loss: 37.4269\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 61.2505 - val_loss: 37.1984\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.0940 - val_loss: 40.2520\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.9417 - val_loss: 37.5693\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 64.8055 - val_loss: 37.9053\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.5248 - val_loss: 39.7156\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.5751 - val_loss: 52.1757\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.1574 - val_loss: 38.2382\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.5811 - val_loss: 37.8920\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.8742 - val_loss: 39.7868\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.1379 - val_loss: 38.9523\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.2907 - val_loss: 41.1333\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.8530 - val_loss: 38.7354\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.1610 - val_loss: 42.3773\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.0207 - val_loss: 55.8233\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.0356 - val_loss: 39.0442\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.0385 - val_loss: 38.0303\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 67.7751 - val_loss: 39.9855\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.9537 - val_loss: 42.8382\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.3746 - val_loss: 41.4002\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.4681 - val_loss: 43.9128\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 64.3955 - val_loss: 39.2787\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.8119 - val_loss: 38.1364\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.1225 - val_loss: 38.6231\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.5586 - val_loss: 43.6645\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 67.5696 - val_loss: 42.2073\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.0516 - val_loss: 67.8444\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.7022 - val_loss: 45.3210\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.6593 - val_loss: 39.4505\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.4666 - val_loss: 39.9025\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.5171 - val_loss: 38.5863\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.7521 - val_loss: 40.2712\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.7022 - val_loss: 38.8130\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.0707 - val_loss: 41.0203\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.0351 - val_loss: 46.7642\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 54.8518 - val_loss: 45.4709\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.8189 - val_loss: 45.2302\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.7754 - val_loss: 42.7455\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 54.9291 - val_loss: 39.6598\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.5558 - val_loss: 38.4455\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.2329 - val_loss: 37.9128\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.8376 - val_loss: 38.6350\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.4441 - val_loss: 40.7178\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.7164 - val_loss: 47.8417\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.3494 - val_loss: 52.7047\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.4146 - val_loss: 45.9212\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.1197 - val_loss: 38.5556\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.3130 - val_loss: 47.4610\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.9721 - val_loss: 54.7118\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 61.6882 - val_loss: 41.7355\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.5550 - val_loss: 38.8987\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.9150 - val_loss: 37.9125\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.1433 - val_loss: 40.3190\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.1027 - val_loss: 45.1487\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.9352 - val_loss: 53.3093\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.1288 - val_loss: 45.2070\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.6535 - val_loss: 38.3305\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.7816 - val_loss: 38.0041\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.9564 - val_loss: 66.2717\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.2050 - val_loss: 43.2573\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.2815 - val_loss: 38.4017\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.2565 - val_loss: 42.5108\n",
      "Epoch 229/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.4345 - val_loss: 37.8258\n",
      "Epoch 230/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.1705 - val_loss: 39.3897\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.4854 - val_loss: 38.4018\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.6934 - val_loss: 37.2182\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.0355 - val_loss: 37.6850\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 59.6938 - val_loss: 38.4475\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.9733 - val_loss: 39.2962\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.6272 - val_loss: 42.3328\n",
      "Epoch 237/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.0446 - val_loss: 40.1155\n",
      "Epoch 238/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.5503 - val_loss: 43.4766\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.2528 - val_loss: 38.9749\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.2614 - val_loss: 38.3562\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.4239 - val_loss: 36.4777\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.7083 - val_loss: 39.4052\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 59.5155 - val_loss: 40.5522\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 65.9688 - val_loss: 42.9398\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.8747 - val_loss: 39.9755\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.5797 - val_loss: 38.8131\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.4809 - val_loss: 37.9212\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.2925 - val_loss: 38.9410\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.9205 - val_loss: 53.6375\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 58.5077 - val_loss: 48.1598\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.1813 - val_loss: 37.9642\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 76.1825 - val_loss: 57.4798\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.2545 - val_loss: 46.7492\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.7849 - val_loss: 38.5936\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.2030 - val_loss: 47.6846\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.9232 - val_loss: 43.7666\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.2431 - val_loss: 41.0993\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.2771 - val_loss: 38.8878\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.8415 - val_loss: 41.1124\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 53.6565 - val_loss: 44.8764\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 55.5488 - val_loss: 38.8113\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.1221 - val_loss: 38.0765\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 53.4986 - val_loss: 50.5755\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 55.8097 - val_loss: 40.5568\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.7419 - val_loss: 36.6578\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.6754 - val_loss: 43.2950\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 54.4740 - val_loss: 37.7175\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.9751 - val_loss: 38.2327\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.1799 - val_loss: 43.2084\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 53.9734 - val_loss: 37.6461\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 53.6499 - val_loss: 39.8426\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 51.8512 - val_loss: 36.7782\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.0048 - val_loss: 39.2499\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 53.0367 - val_loss: 45.2052\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 55.3293 - val_loss: 37.6211\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 53.3271 - val_loss: 36.1886\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.0676 - val_loss: 48.6334\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.3120 - val_loss: 51.7950\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.7140 - val_loss: 39.1151\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.0179 - val_loss: 54.1345\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 62.4329 - val_loss: 35.9671\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 64.1187 - val_loss: 37.2119\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 57.3154 - val_loss: 48.4458\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.6367 - val_loss: 37.5973\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.2133 - val_loss: 38.0131\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.9049 - val_loss: 55.0937\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 53.4210 - val_loss: 36.9723\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 52.7323 - val_loss: 37.4561\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 52.0321 - val_loss: 36.1226\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 52.6765 - val_loss: 37.3334\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.6393 - val_loss: 36.7550\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 54.4019 - val_loss: 35.8678\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.2799 - val_loss: 50.0232\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.3546 - val_loss: 36.4452\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.7264 - val_loss: 40.9456\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.1352 - val_loss: 37.5796\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.6884 - val_loss: 36.4705\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.3502 - val_loss: 35.4174\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.8571 - val_loss: 43.8499\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 55.3613 - val_loss: 35.8980\n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.4263 - val_loss: 37.9006\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.9976 - val_loss: 34.5219\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.4547 - val_loss: 40.1475\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 67.5134 - val_loss: 38.1399\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.6662 - val_loss: 36.4442\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.0850 - val_loss: 38.2776\n",
      "Epoch 307/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 56.6875 - val_loss: 38.8287\n",
      "Epoch 308/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.1025 - val_loss: 39.5711\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 62.9432 - val_loss: 44.2273\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.3509 - val_loss: 38.6367\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.3444 - val_loss: 43.5524\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.1519 - val_loss: 35.8536\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.7585 - val_loss: 46.7475\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.8537 - val_loss: 36.1755\n",
      "Epoch 315/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 51.3979 - val_loss: 45.5183\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.5891 - val_loss: 40.6946\n",
      "Epoch 317/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.4636 - val_loss: 36.4896\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.9153 - val_loss: 38.5956\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 5ms/step - loss: 52.5822 - val_loss: 39.1453\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.7500 - val_loss: 78.7284\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 149.4639 - val_loss: 43.7230\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.1658 - val_loss: 40.4241\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.6326 - val_loss: 43.7043\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.4861 - val_loss: 39.8172\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.7045 - val_loss: 39.6197\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.8174 - val_loss: 45.2746\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.7340 - val_loss: 50.0781\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.2979 - val_loss: 41.8627\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.4353 - val_loss: 37.1072\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.5426 - val_loss: 38.2316\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.3996 - val_loss: 39.0205\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.6539 - val_loss: 37.4701\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.4446 - val_loss: 39.0153\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.9061 - val_loss: 36.4156\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.2135 - val_loss: 37.4656\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.3466 - val_loss: 36.5472\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.0557 - val_loss: 37.6169\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.4728 - val_loss: 37.5232\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.5351 - val_loss: 36.2317\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.0067 - val_loss: 35.9530\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.2748 - val_loss: 36.6771\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.8018 - val_loss: 37.7345\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 59.2822 - val_loss: 35.0755\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 65.4047 - val_loss: 39.5495\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.8735 - val_loss: 37.0175\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.3938 - val_loss: 35.9515\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.1038 - val_loss: 39.2494\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.4325 - val_loss: 53.4357\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.2739 - val_loss: 35.2510\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 49.5108 - val_loss: 35.1768\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.3933 - val_loss: 38.5004\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.3776 - val_loss: 34.8326\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.4053 - val_loss: 36.3209\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.3972 - val_loss: 35.5017\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 54.9186 - val_loss: 48.2790\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.6279 - val_loss: 38.8490\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.7872 - val_loss: 35.7120\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.1932 - val_loss: 35.8366\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.1550 - val_loss: 34.7444\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.1442 - val_loss: 34.9818\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.4946 - val_loss: 35.4790\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 48.6799 - val_loss: 43.4420\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.8669 - val_loss: 39.8950\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 58.1807 - val_loss: 36.9010\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 53.3080 - val_loss: 36.6087\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.1434 - val_loss: 35.7838\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.9383 - val_loss: 37.9778\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 51.7124 - val_loss: 38.1994\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.4314 - val_loss: 44.5430\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.3834 - val_loss: 43.9737\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.6850 - val_loss: 35.1683\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.5181 - val_loss: 35.9243\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.4875 - val_loss: 38.7341\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.7067 - val_loss: 39.8458\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.1057 - val_loss: 34.6379\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.6923 - val_loss: 35.6498\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 57.9620 - val_loss: 35.7939\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 55.5097 - val_loss: 38.9194\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.7979 - val_loss: 36.9176\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.8835 - val_loss: 38.1102\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.2833 - val_loss: 33.9689\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.8915 - val_loss: 31.6130\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.2005 - val_loss: 35.7671\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.9374 - val_loss: 35.5458\n",
      "Epoch 385/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.9047 - val_loss: 33.9537\n",
      "Epoch 386/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.0943 - val_loss: 35.5381\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.8100 - val_loss: 34.7397\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.5775 - val_loss: 38.7582\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.4418 - val_loss: 46.0145\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.2808 - val_loss: 37.1470\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.1825 - val_loss: 34.8399\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.9922 - val_loss: 34.7153\n",
      "Epoch 393/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.0345 - val_loss: 33.4362\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.8258 - val_loss: 39.0738\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.1348 - val_loss: 33.4330\n",
      "Epoch 396/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.4723 - val_loss: 38.0045\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.3232 - val_loss: 37.1167\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.6512 - val_loss: 35.3180\n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 50.7428 - val_loss: 35.3368\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 50.3843 - val_loss: 32.8394\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.5669 - val_loss: 34.6137\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.2824 - val_loss: 38.7147\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.4250 - val_loss: 34.2528\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.4250 - val_loss: 35.2546\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.8733 - val_loss: 37.4078\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.2657 - val_loss: 40.4045\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.5495 - val_loss: 48.1323\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.9416 - val_loss: 37.3270\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.2654 - val_loss: 33.6503\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.2094 - val_loss: 40.4464\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.0102 - val_loss: 37.0865\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 56.3300 - val_loss: 36.0754\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.6926 - val_loss: 40.5210\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.5109 - val_loss: 34.7377\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.3585 - val_loss: 40.8601\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.4149 - val_loss: 33.6544\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.1356 - val_loss: 41.2547\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 47.7500 - val_loss: 32.4997\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.2767 - val_loss: 34.8274\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.9118 - val_loss: 35.3253\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 47.2137 - val_loss: 36.3667\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.6080 - val_loss: 31.2581\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 47.6974 - val_loss: 32.9113\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 47.2634 - val_loss: 38.0335\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.3345 - val_loss: 39.0834\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.3848 - val_loss: 34.3194\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.2379 - val_loss: 36.0699\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.3503 - val_loss: 33.2966\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.8786 - val_loss: 32.7765\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 46.4583 - val_loss: 40.9827\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.6346 - val_loss: 35.1820\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.7127 - val_loss: 38.4652\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 63.7294 - val_loss: 39.1857\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 53.6029 - val_loss: 40.7806\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.4135 - val_loss: 43.2908\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.1141 - val_loss: 42.6409\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.2156 - val_loss: 33.2714\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 46.5375 - val_loss: 32.9834\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 47.9450 - val_loss: 41.6752\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 46.7708 - val_loss: 38.1128\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 45.9949 - val_loss: 33.0807\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.5853 - val_loss: 35.5341\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.2744 - val_loss: 32.6576\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.0143 - val_loss: 36.9265\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 54.7513 - val_loss: 34.7919\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.9462 - val_loss: 39.7275\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.7939 - val_loss: 35.7356\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 55.5224 - val_loss: 40.2283\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.2217 - val_loss: 34.6237\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.4392 - val_loss: 66.8574\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 109.9380 - val_loss: 49.4786\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.5828 - val_loss: 39.5561\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.2469 - val_loss: 39.4069\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.7327 - val_loss: 35.3909\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 51.7409 - val_loss: 35.5206\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 51.7213 - val_loss: 36.2935\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 60.3882 - val_loss: 36.3706\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.6513 - val_loss: 35.1099\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.2523 - val_loss: 38.1199\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 48.5196 - val_loss: 35.6014\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 47.1191 - val_loss: 34.3684\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 46.8741 - val_loss: 33.9963\n",
      "Epoch 463/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 46.2183 - val_loss: 36.3973\n",
      "Epoch 464/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.1396 - val_loss: 36.6998\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.0421 - val_loss: 40.1282\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.1602 - val_loss: 35.1454\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.9954 - val_loss: 37.6971\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 48.3713 - val_loss: 33.0482\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 47.2964 - val_loss: 34.1639\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.5354 - val_loss: 38.1474\n",
      "Epoch 471/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 46.0994 - val_loss: 36.7329\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 48.8298 - val_loss: 34.6075\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.6376 - val_loss: 33.7070\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.8225 - val_loss: 43.0419\n",
      "Epoch 475/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 47.5255 - val_loss: 39.4647\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.8829 - val_loss: 35.7574\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 5ms/step - loss: 47.2801 - val_loss: 34.9015\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 47.2641 - val_loss: 35.7107\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.2977 - val_loss: 36.4571\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 65.3626 - val_loss: 35.0513\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 47.1161 - val_loss: 36.3457\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.2332 - val_loss: 37.3138\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.0937 - val_loss: 33.6841\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 50.8629 - val_loss: 41.2862\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 47.2010 - val_loss: 36.3728\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 46.4079 - val_loss: 33.8083\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.4605 - val_loss: 36.4647\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.0379 - val_loss: 40.6913\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 47.2223 - val_loss: 32.6669\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 46.3422 - val_loss: 36.7407\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 45.6600 - val_loss: 46.6844\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 105.4321 - val_loss: 48.1769\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 58.7891 - val_loss: 39.2458\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.7552 - val_loss: 37.6831\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 52.9137 - val_loss: 38.2840\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 49.2847 - val_loss: 42.7450\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 48.0700 - val_loss: 42.8200\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.8606 - val_loss: 34.3613\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 51.0552 - val_loss: 34.9538\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 48.6899 - val_loss: 33.4887\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               3000      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 500)               250500    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,005,501\n",
      "Trainable params: 1,005,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=10,epochs=500)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cad2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49b87979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7539209920176537"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0c127e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.786938719066521"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(tahmin,y_test))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dd60929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_test(x,y):\n",
    "    L = LinearRegression()\n",
    "    E = ElasticNet()\n",
    "    R = Ridge()\n",
    "    Lass = Lasso()\n",
    "    ETR=ExtraTreeRegressor()\n",
    "    GBR=GradientBoostingRegressor()\n",
    "    XGBC= XGBRegressor()\n",
    "    x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.2,random_state=13)\n",
    "    algos = [L,E,R,Lass,ETR,GBR,XGBC]\n",
    "    algo_names = ['Linear','ElasticNet','Ridge','Lasso','Extra Tree','Gradient Boosting','XGradientBooting']\n",
    "    r_squared = []\n",
    "    rmse = []\n",
    "    mae = []\n",
    "    result = pd.DataFrame(columns = ['R_Squared','RMSE','MAE'],index = algo_names)\n",
    "    for algo in algos:\n",
    "        algo.fit(x_train,y_train)    \n",
    "        r_squared.append(r2_score(y_test,algo.predict(x_test)))\n",
    "        rmse.append(mean_squared_error(y_test, algo.predict(x_test))**.5)\n",
    "        mae.append(mean_absolute_error(y_test, algo.predict(x_test)))\n",
    "    result.R_Squared = r_squared\n",
    "    result.RMSE = rmse\n",
    "    result.MAE= mae\n",
    "    return result.sort_values('R_Squared', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43d1ef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.709863</td>\n",
       "      <td>6.206374</td>\n",
       "      <td>4.659893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGradientBooting</th>\n",
       "      <td>0.679097</td>\n",
       "      <td>6.527153</td>\n",
       "      <td>4.584120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.606167</td>\n",
       "      <td>7.230905</td>\n",
       "      <td>5.685921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>0.602466</td>\n",
       "      <td>7.264798</td>\n",
       "      <td>5.667934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Tree</th>\n",
       "      <td>0.499598</td>\n",
       "      <td>8.150727</td>\n",
       "      <td>5.625201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.382042</td>\n",
       "      <td>9.057662</td>\n",
       "      <td>7.005038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.148782</td>\n",
       "      <td>10.630585</td>\n",
       "      <td>8.466267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   R_Squared       RMSE       MAE\n",
       "Gradient Boosting   0.709863   6.206374  4.659893\n",
       "XGradientBooting    0.679097   6.527153  4.584120\n",
       "Ridge               0.606167   7.230905  5.685921\n",
       "Linear              0.602466   7.264798  5.667934\n",
       "Extra Tree          0.499598   8.150727  5.625201\n",
       "Lasso               0.382042   9.057662  7.005038\n",
       "ElasticNet          0.148782  10.630585  8.466267"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_test(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f33cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
